{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 本章内容介绍\n",
    "\n",
    "奇异值分解(Singular Value Decomposition,SVD)常用来简化数据、去除噪声。在这章先介绍SVD的一些应用，再从其算法来分析它为什么有效，然后建立一个基于协同过滤的系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 奇异值分解的应用\n",
    "\n",
    "在隐性语义索引中(Latent Semantic Indexing，LSI)，我们将一个文档用一个矩阵(term-document)表示，在这个矩阵的基础上运用SVD对其分解，便可以得到它的某个低秩逼近，在这个低秩逼近下，可以为每个文档产生一个新的表示(奇异值)。这些奇异值代表了文档的概念或者主题，因此可以用于加快文档检索。\n",
    "\n",
    "另一个应用就是推荐系统。SVD可以从数据中构建一个主题空间，然后在这个空间中计算它的相似度。具体的实现将在后面进行讲解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 矩阵分解\n",
    "\n",
    "SVD是矩阵分解的一种类型，矩阵分解的目的是将矩阵分成多个独立的部分。我们可以将这种分解的过程想象成代数中的因子分解。如何将12分解成两个数的乘积？(1,12)(2,6)(3,4)都是合理的答案。\n",
    "\n",
    "不同矩阵分解技术有不同的性质，运用于不同方面，而SVD则是最常见的一种分解技术。它将矩阵$Data$分解成三个矩阵$U 、\\Sigma和V^T$\n",
    "\n",
    "假如矩阵$Data$的维度是$m \\times n$，$U 、\\Sigma和V^T$这三个矩阵的维度分别是$m \\times m、m \\times n 、n \\times n$，所以用公式表达就是\n",
    "\n",
    "$$Data_{m \\times n} = U_{m \\times m}\\Sigma_{m \\times n}V^T_{n \\times n}$$\n",
    "\n",
    "其中$\\Sigma$是一个对角矩阵，也就是奇异值矩阵，而且其对角元素是从大到小排列的，被称为奇异值。而且在科学和工程中，一直存在着一个普遍的事实：在某个奇异值的数目($r$个)之后，其他奇异值都置为0。这意味着数据集中仅有$r$个重要特征，而其余特征都是噪声或者是冗余特征。$U$被称为左奇异矩阵，$V^T$则是右奇异矩阵，两者都是单位正交矩阵。SVD的目的是，对任意$m\\times n$的矩阵，找到一组正交基使得经过它变换后还是正交基。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用Python实现SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.14142136 -0.98994949]\n",
      " [-0.98994949  0.14142136]]\n",
      "[[-0.70710678 -0.70710678]\n",
      " [-0.70710678  0.70710678]]\n",
      "[10.  0.]\n",
      "[[10.  0.]\n",
      " [ 0.  0.]]\n",
      "[[1. 1.]\n",
      " [7. 7.]]\n"
     ]
    }
   ],
   "source": [
    "#导入需要的库与包\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n",
    "#创建矩阵\n",
    "Data = np.array([[1,1],[7,7]])\n",
    "\n",
    "m = Data.shape[0]#矩阵的行数\n",
    "n = Data.shape[1]#矩阵的列数\n",
    "\n",
    "#调用linalg包中封装好的SVD算法\n",
    "U,Sigma,VT = linalg.svd(Data)\n",
    "\n",
    "print(U)\n",
    "print(VT)\n",
    "print(Sigma)\n",
    "\n",
    "#我们需要构建一个mxn的Sigma矩阵，但是我们并不知道返回的特征值有多少个，因此要在后面补充零\n",
    "if m > n:\n",
    "    for i in range(m - len(Sigma)):\n",
    "        Sigma = np.append(Sigma,0)\n",
    "else:\n",
    "    for i in range(n - len(Sigma)):\n",
    "        Sigma = np.append(Sigma,0)\n",
    "#注意：linalg为了节省空间，对角矩阵以一维向量返回，因此需使用np.diag将一维向量转换成对角矩阵，然后再取前m行，前n列\n",
    "print(np.diag(Sigma)[:m,:n])\n",
    "rData = np.dot(np.dot(U,np.diag(Sigma)[:m,:]),VT)\n",
    "print(rData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadExData():\n",
    "    '''\n",
    "    函数功能：加载数据\n",
    "    参数说明：\n",
    "            None\n",
    "    函数返回：\n",
    "            相应数据\n",
    "    '''\n",
    "    return np.array([\n",
    "        [1, 1, 1, 0, 0],\n",
    "        [2, 2, 2, 0, 0],\n",
    "        [1, 1, 1, 0, 0],\n",
    "        [5, 5, 5, 0, 0],\n",
    "        [1, 1, 0, 2, 2],\n",
    "        [0, 0, 0, 3, 3],\n",
    "        [0, 0, 0, 1, 1]\n",
    "    ])#为了方便运算，使用array格式\n",
    "\n",
    "Data = loadExData()\n",
    "m = Data.shape[0]#矩阵的行数\n",
    "n = Data.shape[1]#矩阵的列数\n",
    "U,Sigma,VT = linalg.svd(Data)#调用linalg中封装好的svd函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "奇异值越大的时候，代表的信息越多，可以观察到后两个数值非常小，我们可以将它们去掉，那么原始数据集$Data$与分解出来的矩阵$U 、\\Sigma和V^T$的关系就变成了近似关系。\n",
    "\n",
    "即:\n",
    "\n",
    "$$Data_{m \\times n} \\approx U_{m \\times m}\\Sigma_{m \\times n}V^T_{n \\times n}$$\n",
    "\n",
    "但是就算后面的数值再小，当我们去掉越多这样奇异值，我们的近似关系会变得不理想。\n",
    "\n",
    "不过，我们可以观察到，奇异值是下降非常快的。一般来说取前30%左右的奇异值就能还原绝大部分的数据。我们也可以根据我们想要保留的数据程度选择奇异值的数量，这跟PCA非常相似。\n",
    "\n",
    "我们去除后面两个奇异值之后，采用前面三个奇异值来重新构建$Data$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         -2.84366098e-16, -2.94015497e-16],\n",
       "        [ 2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "          4.47489534e-16,  4.28190736e-16],\n",
       "        [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "          3.09573758e-16,  2.99924358e-16],\n",
       "        [ 5.00000000e+00,  5.00000000e+00,  5.00000000e+00,\n",
       "         -1.47703573e-16, -1.95842150e-16],\n",
       "        [ 1.00000000e+00,  1.00000000e+00, -5.70229711e-16,\n",
       "          2.00000000e+00,  2.00000000e+00],\n",
       "        [-7.49390630e-17,  9.96896569e-16, -1.34350906e-15,\n",
       "          3.00000000e+00,  3.00000000e+00],\n",
       "        [-8.18314124e-17,  2.75447132e-16, -3.13743829e-16,\n",
       "          1.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#构建奇异值矩阵\n",
    "Sig3 = np.mat([[Sigma[0],0,0],[0,Sigma[1],0],[0,0,Sigma[2]]])\n",
    "#因为上面用的是np.mat构建的矩阵，采用*号的乘法是矩阵相乘\n",
    "U[:,:3]*Sig3*VT[:3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于$Sig$只是$3x3$矩阵，因此也只需要使用矩阵$U$的前$3$列与$V^T$的前三行。可以看到重构出来的矩阵与原始矩阵的数值非常接近。\n",
    "\n",
    "如果你不理解为什么只需要使用矩阵$U$的前$3$列与$V^T$的前三行，也可以看下面的代码，我们沿用上面重构矩阵的代码展示Sigma的值。\n",
    "\n",
    "可以看到Sigma应该是一个$m \\times n$矩阵，但是只有左上角才存在值其余都为零。显然，一整列或行都是零的话，在矩阵相乘运算中得到的结果也是零，对结果不产生影响 。因此可以取矩阵$U$的前$3$列与$V^T$的前三行简化计算，也可以节省空间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.72140007 0.         0.         0.         0.        ]\n",
      " [0.         5.29397912 0.         0.         0.        ]\n",
      " [0.         0.         0.68422636 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "        -2.84366098e-16, -2.94015497e-16],\n",
       "       [ 2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "         4.47489534e-16,  4.28190736e-16],\n",
       "       [ 1.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         3.09573758e-16,  2.99924358e-16],\n",
       "       [ 5.00000000e+00,  5.00000000e+00,  5.00000000e+00,\n",
       "        -1.47703573e-16, -1.95842150e-16],\n",
       "       [ 1.00000000e+00,  1.00000000e+00, -5.70229711e-16,\n",
       "         2.00000000e+00,  2.00000000e+00],\n",
       "       [-7.49390630e-17,  9.96896569e-16, -1.34350906e-15,\n",
       "         3.00000000e+00,  3.00000000e+00],\n",
       "       [-8.18314124e-17,  2.75447132e-16, -3.13743829e-16,\n",
       "         1.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sig = Sigma[:3]#取前3个特征值\n",
    "if m > n:\n",
    "    for i in range(m - len(Sig)):\n",
    "        Sig = np.append(Sig,0)\n",
    "else:\n",
    "    for i in range(n - len(Sig)):\n",
    "        Sig = np.append(Sig,0)\n",
    "print(np.diag(Sig)[:m,:n])\n",
    "np.dot(np.dot(U,np.diag(Sig)[:m,:n]),VT)#现在的数据类型是numpy.array,所以要用np.dot()进行矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到两种计算方法得出的结果是一致的，而且显然U[:,:3]*Sig3*VT[:3,:]需要的存储空间、运算次数都要比np.dot(np.dot(U,np.diag(Sig)[:m,:n]),VT)少，因此是推荐使用U[:,:3]*Sig3*VT[:3,:]来进行计算。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于协同过滤的推荐引擎\n",
    "在聚类的时候，我们知道，非常相近或相似的数据容易被归成一类。在这里，我们也可以通过计算用户或物品之间的相似度，得到用户或物品之间的相似度。这样就可以预测到未知的用户的喜好。比如,我们尝试对某个用户喜欢的电影进行预测，推荐引擎会发现有一部电影该用户没看过，然后计算该电影与用户看过的电影之间的相似度，如果其相似度很高，推荐算法就认为用户喜欢这部电影。\n",
    "\n",
    "所以我们得先了解一下相似度应该怎么计算。\n",
    "\n",
    "在聚类当中，相似度可以通过距离来体现。在这里也是如此。最常见的距离度量就是欧氏距离。\n",
    "对于下面这个矩阵：\n",
    "\n",
    "$\\begin{matrix} & 鳗鱼饭 & 日式炸鸡排 &  寿司饭 & 烤牛肉 & 手撕猪肉 \\\\\n",
    "Jim & 2 & 0 & 0 & 4 & 4\\\\\n",
    "John & 5 & 5 & 5 & 3 & 3 \\\\\n",
    "Sally & 2 & 4 & 2 & 1 & 2 \\\\\n",
    "\\end{matrix}$\n",
    "\n",
    "我们用欧氏距离来计算手撕猪肉和烤牛肉之间的相似度：\n",
    "\n",
    "$$\\sqrt{(4-4)^2+(3-3)^2+(2-1)^2} = 1$$\n",
    "\n",
    "而手撕猪肉和鳗鱼饭的欧氏距离为：\n",
    "\n",
    "$$\\sqrt{(4-2)^2+(3-5)^2+(2-2)^2} = 2.83$$\n",
    "\n",
    "我们可以将距离归一化到$(0,1]$之间。当距离为$0$时，相似度为$1$.如果距离非常大，那么相似度也趋于$0$.\n",
    "\n",
    "$$相似度 = \\frac{1}{1+距离}$$\n",
    "\n",
    "第二种可以用来计算距离的方法是皮尔逊相关系数。皮尔逊系数相对于欧氏距离有个优势在于，它对用户评级的量级不敏感。比如说一个人对所有物品的评分都是5分，而另一个人对所有物品的评分是1分，皮尔逊相关系数会认为这两个向量是相等的。皮尔逊相关系数的取值范围在$[-1,+1]$之间，我们用$0.5+0.5*corrcoef()$计算它并将它归一化到0到1之间。\n",
    "\n",
    "第三种则是余弦相似度，它计算两个向量夹角的余弦值，如果夹角为$90^o$，则相似度为0;如果两个向量的方向相同，其相似度就为$1$。余弦相似度的取值范围也在$-1$到$1$之间\n",
    "\n",
    "向量$A$与$B$夹角的余弦相似度计算如下：\n",
    "$$cos\\theta = \\frac{A\\cdot B}{\\left\\|A\\right\\|\\left\\|B\\right\\|}$$\n",
    "\n",
    "$\\left\\|A\\right\\|$、$\\left\\|B\\right\\|$表示向量$A、B$的$2$范数.我们可以使用linalg.norm()来计算它\n",
    "\n",
    "这三种计算相似度的方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecludSim(inA,inB):\n",
    "    '''\n",
    "    函数功能：计算欧氏距离相似度\n",
    "    参数说明：\n",
    "            inA__输入的向量A\n",
    "            inB__输入的向量B\n",
    "    函数返回：\n",
    "            两个向量之间的欧氏距离\n",
    "    '''\n",
    "    return 1.0/(1.0 + linalg.norm(inA - inB))\n",
    "\n",
    "def pearsSim(inA,inB):\n",
    "    '''\n",
    "    函数功能：计算皮尔逊相似度，并将其归一化\n",
    "    参数说明：\n",
    "            inA__输入的向量A\n",
    "            inB__输入的向量B\n",
    "    函数返回：\n",
    "            两个向量之间的归一化的皮尔逊系数\n",
    "    '''\n",
    "    if len(inA) < 3 : \n",
    "        return 1.0\n",
    "    return 0.5 + 0.5 * np.corrcoef(inA, inB, rowvar = 0)[0][1]\n",
    "\n",
    "def cosSim(inA,inB):\n",
    "    '''\n",
    "    函数功能：计算余弦逊相似度，并将其归一化\n",
    "    参数说明：\n",
    "            inA__输入的向量A\n",
    "            inB__输入的向量B\n",
    "    函数返回：\n",
    "            两个向量之间的归一化的余弦相似度\n",
    "    '''\n",
    "    num = float(inA.T*inB)\n",
    "    denom = linalg.norm(inA)*linalg.norm(inB)\n",
    "    return 0.5+0.5*(num/denom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ecludSim()函数是用来计算欧氏距离相似度的。\n",
    "\n",
    "pearSim()函数则是用来计算皮尔逊相关系数，并且将其归一化到0和1之间。有些人可能不明白，为什么len(inA)<3会返回1。\n",
    "首先需要知道皮尔逊相关系数可以表示两个变量的相关程度，大于0为正相关，小于0为负相关。当皮尔逊系数为1时，这两个变量完全正相关;当皮尔逊系数为-1时，这两个变量完全负相关。而当这个变量只有两个数的时候，这个变量要么是递增，要么是递减的，同理另一个变量也是如此。所以这两个变量要么是完全负相关，要么是完全正相关。因此返回1。(如果有个变量是没有变化的，那标准差为0，无法计算皮尔逊相关系数)\n",
    "\n",
    "cosSim()则是用来计算余弦相似度\n",
    "\n",
    "下面来对这些计算方法进行尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMat = np.mat(loadExData())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13367660240019172"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecludSim(myMat[:,0],myMat[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecludSim(myMat[:,0],myMat[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5472455591261534"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSim(myMat[:,0],myMat[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosSim(myMat[:,0],myMat[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23768619407595815"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsSim(myMat[:,0],myMat[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsSim(myMat[:,0],myMat[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那计算相似度的方法有了，接下来是计算用户相似度或物品相似度。那么我们究竟要基于物品的相似度还是基于用户的相似度构建我们的推荐引擎呢？相似度计算的时间会随着数据的增大而增大，如果用户的数目非常多，那么就可能会选择基于物品相似度的计算方法。\n",
    "\n",
    "对于大部分产品导向的推荐引擎而言，用户的数量往往大于物品的数量。我们可以根据需求选择。\n",
    "\n",
    "那么推荐引擎的好坏该用什么评价呢？我们可以对一些人的评分进行遮掩，然后对其进行预测，最后计算预测值与真实值之间的差距。书中所用的评价指标是$最小均方根误差(Root Mean Squared，RMSE)$，它先计算均方误差的平均值再对其取平方根。如果评级在1到5星这个范围内，而RMSE为1，那么意味着我们的预测值和用户的真实值相差了1星。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 示例：餐馆菜肴推荐引擎\n",
    "我们先来构建一个基本的推荐引擎，它可以寻找用户没有尝过的菜肴，然后通过SVD来减少特征空间，并提高推荐的效果。\n",
    "\n",
    "这个推荐系统的工作过程是：\n",
    "\n",
    "(1)寻找用户没有评级的菜肴，即用户-物品矩阵中的0值\n",
    "\n",
    "(2)在用户没有评级的所有物品当中，对每一个物品预计一个可能的评级分数。\n",
    "\n",
    "(3)对这些物品的评分从高到低进行排序，返回前$N$个物品\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standEst(dataMat, user, simMeas, item):\n",
    "    '''\n",
    "    函数功能：通过物品评分的相似度来计算用户未评分过的物品\n",
    "    参数说明：\n",
    "            dataMat__用户-物品评分矩阵\n",
    "            user__第user个用户(从0开始算)\n",
    "            simMeas__计算相似度的函数，默认是cosSim()\n",
    "            item__该用户未进行评分的物品\n",
    "    函数返回：\n",
    "            item的分数\n",
    "    '''\n",
    "    #item是该user还未评分的物品，j则是该user已评分的物品。通过计算与其他用户评分的相似度，得出该user还未评分的相似。\n",
    "    n = np.shape(dataMat)[1]#物品数量\n",
    "    simTotal = 0.0#相似度总和\n",
    "    ratSimTotal = 0.0#评分总和\n",
    "    for j in range(n):\n",
    "        print(item,j)\n",
    "        #user对第j个物品的评分\n",
    "        userRating = dataMat[user,j]\n",
    "        #为0则跳出本次循环\n",
    "        if userRating == 0: \n",
    "            continue\n",
    "        #overlap是两个物品当中已经被评分的用户\n",
    "        overLap = np.nonzero(np.logical_and(dataMat[:,item].A>0, dataMat[:,j].A>0))[0]\n",
    "        #如果没有user未评分的物品评过分的用户，那么similarity是0\n",
    "        if len(overLap) == 0:\n",
    "            similarity = 0\n",
    "        else:\n",
    "            #基于这些重合的物品计算用户与user之间的相似度\n",
    "            similarity = simMeas(dataMat[overLap,item], dataMat[overLap,j])\n",
    "        print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        #计算总相似度\n",
    "        simTotal += similarity\n",
    "        #相似度乘上userRating\n",
    "        ratSimTotal += similarity * userRating\n",
    "\n",
    "    if simTotal == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        print('uR',ratSimTotal/simTotal)\n",
    "        #除以总相似度\n",
    "        return ratSimTotal/simTotal\n",
    "\n",
    "def recommend(dataMat, user, N=3, simMeas=cosSim, estMethod=standEst):\n",
    "    '''\n",
    "    函数功能：通过物品评分的相似度来计算用户未评分过的物品，并返回分数最高的前N个物品\n",
    "    参数说明：\n",
    "            dataMat__用户-物品评分矩阵\n",
    "            user__第user个用户(从0开始算)\n",
    "            N__分数最高的前N个物品\n",
    "            simMeas__计算相似度的函数，默认是cosSim()\n",
    "            estMethod__计算未评分物品相似度的函数，默认是standEst()\n",
    "    函数返回：\n",
    "            分数最高的前N个物品\n",
    "    '''\n",
    "    unratedItems = np.nonzero(dataMat[user,:].A==0)[1]#find unrated items \n",
    "    if len(unratedItems) == 0:\n",
    "        return 'you rated everything'\n",
    "    itemScores = []\n",
    "    for item in unratedItems:\n",
    "        estimatedScore = estMethod(dataMat, user, simMeas, item)\n",
    "        print(estimatedScore)\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[4, 4, 0, 2, 2],\n",
       "        [4, 0, 0, 3, 3],\n",
       "        [4, 0, 0, 1, 1],\n",
       "        [1, 1, 1, 2, 0],\n",
       "        [2, 2, 2, 0, 0],\n",
       "        [1, 1, 1, 0, 0],\n",
       "        [5, 5, 5, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myMat = np.mat([\n",
    "    [4, 4, 0, 2, 2],\n",
    "    [4, 0, 0, 3, 3],\n",
    "    [4, 0, 0, 1, 1],\n",
    "    [1, 1, 1, 2, 0],\n",
    "    [2, 2, 2, 0, 0],\n",
    "    [1, 1, 1, 0, 0],\n",
    "    [5, 5, 5, 0, 0]\n",
    "])\n",
    "myMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "the 1 and 0 similarity is: 1.000000\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "the 1 and 3 similarity is: 0.928746\n",
      "1 4\n",
      "the 1 and 4 similarity is: 1.000000\n",
      "uR 2.0243290220056256\n",
      "2.0243290220056256\n",
      "2 0\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "the 2 and 3 similarity is: 1.000000\n",
      "2 4\n",
      "the 2 and 4 similarity is: 0.000000\n",
      "uR 2.5\n",
      "2.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 2.5), (1, 2.0243290220056256)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "the 1 and 0 similarity is: 1.000000\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "the 1 and 3 similarity is: 0.309017\n",
      "1 4\n",
      "the 1 and 4 similarity is: 0.333333\n",
      "uR 2.8266504712098603\n",
      "2.8266504712098603\n",
      "2 0\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "the 2 and 3 similarity is: 0.500000\n",
      "2 4\n",
      "the 2 and 4 similarity is: 0.000000\n",
      "uR 3.0\n",
      "3.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 3.0), (1, 2.8266504712098603)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat,2,simMeas=ecludSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0\n",
      "the 1 and 0 similarity is: 1.000000\n",
      "1 1\n",
      "1 2\n",
      "1 3\n",
      "the 1 and 3 similarity is: 1.000000\n",
      "1 4\n",
      "the 1 and 4 similarity is: 1.000000\n",
      "uR 2.0\n",
      "2.0\n",
      "2 0\n",
      "the 2 and 0 similarity is: 1.000000\n",
      "2 1\n",
      "2 2\n",
      "2 3\n",
      "the 2 and 3 similarity is: 1.000000\n",
      "2 4\n",
      "the 2 and 4 similarity is: 0.000000\n",
      "uR 2.5\n",
      "2.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(2, 2.5), (1, 2.0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(myMat,2,simMeas=pearsSim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些人可能不理解为什么similarity * userRating可以计算出$user$未评分的物品的分数\n",
    "\n",
    "对于上面这个矩阵\n",
    "\n",
    "$\\begin{matrix}\n",
    " &j& item & &  &\\\\\n",
    " &\\textbf{4} & \\textbf{4} & 0 & 2 & 2\\\\\n",
    " &\\textbf{4} & 0 & 0 & 3 & 3\\\\\n",
    " user&\\textbf{4} & 0 & 0 & 1 & 1\\\\\n",
    " &\\textbf{1} & \\textbf{1} & 1 & 2 & 0\\\\\n",
    " &\\textbf{2} & \\textbf{2} & 2 & 0 & 0\\\\\n",
    " &\\textbf{1} & \\textbf{1} & 1 & 0 & 0\\\\\n",
    " &\\textbf{5} & \\textbf{5} & 5 & 0 & 0\\\\\n",
    "\\end{matrix}$\n",
    "\n",
    "我们找出一个样例来看一下\n",
    "\n",
    "对于user=2,item=1,j=0的情况，userRating的值应该是4。\n",
    "\n",
    "similarity是指物品j与物品item之间的相似度。\n",
    "\n",
    "假如说物品j与物品item是一模一样的，那么按道理两者的评分应该相同。同理，两个物品越相似，评分就应该越接近。\n",
    "\n",
    "所以应有：\n",
    "\n",
    "$$item分数 \\approx userRating * similarity$$\n",
    "\n",
    "至于为什么要计算多个物品，这是因为结果可以足够稳定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用SVD提高推荐的效果\n",
    "\n",
    "实际上，在运用中的数据集会的零的个数远远大于现在举的例子。比如某宝数十万的商品，大多数人购买过的不过数十种。对于如此稀疏的矩阵，就这样运行，速度会非常非常慢。\n",
    "\n",
    "你还记得SVD可以简化数据的功能吗？我们可以对这个数据用SVD进行简化，得到一个更小的矩阵。\n",
    "\n",
    "对于下面这个矩阵\n",
    "\n",
    "$\\begin{matrix} & 鳗鱼饭 & 日式炸鸡排 &  寿司饭 & 烤牛肉 & 三文鱼汉堡 & 鲁滨三明治 & 印度烤鸡 & 麻婆豆腐 & 宫保鸡丁 & 印度奶酪咖喱 & 俄式汉堡\\\\\n",
    "Brett & 2 & 0 & 0 & 4 & 4 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "Rob  & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 5 \\\\\n",
    "Drew & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 1 & 0 & 4 & 0 \\\\\n",
    "Scott & 3 & 3 & 4 & 0 & 3 & 0 & 0 & 2 & 2 & 0 & 0 \\\\\n",
    "Mary & 5 & 5 & 5 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "Brent & 0 & 0 & 0 & 0 & 0 & 0 & 5 & 0 & 0 & 5 & 0 \\\\\n",
    "Kyle & 4 & 0 & 4 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 5 \\\\\n",
    "Sara & 0 & 0 & 0 & 0 & 0 & 4 & 0 & 0 & 0 & 0 & 4 \\\\\n",
    "Shaney & 0 & 0 & 0 & 0 & 0 & 0 & 5 & 0 & 0 & 5 & 0 \\\\\n",
    "Brendan & 0 & 0 & 0 & 3 & 0 & 0 & 0 & 0 & 4 & 5 & 0 \\\\\n",
    "Leanna & 1 & 1 & 2 & 1 & 1 & 2 & 1 & 0 & 4 & 5 & 0 \\\\\n",
    "\\end{matrix}$\n",
    "\n",
    "我用书上的数据以及作者提供的loadExData2()中的数据进行了尝试，并未得出跟书中一致的结果，但我们也能明白作者的意思。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.mat([\n",
    "    [2 , 0 , 0 , 4 , 4 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    [0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 5],\n",
    "    [0 , 0 , 0 , 0 , 0 , 0 , 0 , 1 , 0 , 4 , 0],\n",
    "    [3 , 3 , 4 , 0 , 3 , 0 , 0 , 2 , 2 , 0 , 0],\n",
    "    [5 , 5 , 5 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 0],\n",
    "    [0 , 0 , 0 , 0 , 0 , 0 , 5 , 0 , 0 , 5 , 0],\n",
    "    [4 , 0 , 4 , 0 , 0 , 0 , 0 , 0 , 0 , 0 , 5],\n",
    "    [0 , 0 , 0 , 0 , 0 , 4 , 0 , 0 , 0 , 0 , 4],\n",
    "    [0 , 0 , 0 , 0 , 0 , 0 , 5 , 0 , 0 , 5 , 0],\n",
    "    [0 , 0 , 0 , 3 , 0 , 0 , 0 , 0 , 4 , 5 , 0],\n",
    "    [1 , 1 , 2 , 1 , 1 , 2 , 1 , 0 , 4 , 5 , 0]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "U,Sigma,VT = linalg.svd(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34342819e+01, 1.18190832e+01, 8.20176076e+00, 6.86912480e+00,\n",
       "       5.29063022e+00, 3.91213561e+00, 2.94562509e+00, 2.35486137e+00,\n",
       "       2.08702082e+00, 7.08715931e-01, 9.55177878e-17])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sig2 = Sigma ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496.99999999999983"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Sig2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "447.29999999999984"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Sig2)*0.90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320.17065834028847"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Sig2[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462.615181528794"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Sig2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们要取前五个奇异值才能还原原数据的90%。然后我们把这11维的矩阵转换成一个5维的矩阵。在这个五维空间里构建一个相似度计算函数。通过计算\n",
    "\n",
    "代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svdEst(dataMat, user, simMeas, item):\n",
    "    '''\n",
    "    函数功能：对数据进行降维，然后通过物品评分的相似度来计算用户未评分过的物品\n",
    "    参数说明：\n",
    "            dataMat__用户-物品评分矩阵\n",
    "            user__第user个用户(从0开始算)\n",
    "            simMeas__计算相似度的函数，默认是cosSim()\n",
    "            item__该用户未进行评分的物品\n",
    "    函数返回：\n",
    "            item的分数\n",
    "    '''\n",
    "    n = np.shape(dataMat)[1]\n",
    "    simTotal = 0.0\n",
    "    ratSimTotal = 0.0\n",
    "    U,Sigma,VT = linalg.svd(dataMat)\n",
    "    Sig5 = np.mat(np.eye(5)*Sigma[:5])\n",
    "    xformedItems = dataMat.T * U[:,:5] * Sig5.I#将物品转换到低维空间中 Sig5.I是Sig5矩阵的逆矩阵，即对角元素的倒数\n",
    "    #下面这部分计算与standEst()函数的计算步骤几乎相同\n",
    "    for j in range(n):\n",
    "        userRating = dataMat[user,j]\n",
    "        if userRating == 0 or j==item:\n",
    "            continue\n",
    "        similarity = simMeas(xformedItems[item,:].T, xformedItems[j,:].T)\n",
    "        print('the %d and %d similarity is: %f' % (item, j, similarity))\n",
    "        simTotal += similarity\n",
    "        ratSimTotal += similarity * userRating\n",
    "    if simTotal == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return ratSimTotal/simTotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 3 and 0 similarity is: 0.582761\n",
      "the 3 and 1 similarity is: 0.342510\n",
      "the 3 and 2 similarity is: 0.374128\n",
      "the 3 and 4 similarity is: 0.951521\n",
      "the 3 and 7 similarity is: 0.631617\n",
      "the 3 and 8 similarity is: 0.637466\n",
      "2.745751598145099\n",
      "the 5 and 0 similarity is: 0.413406\n",
      "the 5 and 1 similarity is: 0.398870\n",
      "the 5 and 2 similarity is: 0.536319\n",
      "the 5 and 4 similarity is: 0.344640\n",
      "the 5 and 7 similarity is: 0.422636\n",
      "the 5 and 8 similarity is: 0.803996\n",
      "2.7635805374270137\n",
      "the 6 and 0 similarity is: 0.578040\n",
      "the 6 and 1 similarity is: 0.469299\n",
      "the 6 and 2 similarity is: 0.485261\n",
      "the 6 and 4 similarity is: 0.544577\n",
      "the 6 and 7 similarity is: 0.418756\n",
      "the 6 and 8 similarity is: 0.223203\n",
      "2.9423719965834185\n",
      "the 9 and 0 similarity is: 0.443178\n",
      "the 9 and 1 similarity is: 0.509364\n",
      "the 9 and 2 similarity is: 0.516620\n",
      "the 9 and 4 similarity is: 0.448957\n",
      "the 9 and 7 similarity is: 0.573408\n",
      "the 9 and 8 similarity is: 0.738655\n",
      "2.7537467693433197\n",
      "the 10 and 0 similarity is: 0.584526\n",
      "the 10 and 1 similarity is: 0.342595\n",
      "the 10 and 2 similarity is: 0.553617\n",
      "the 10 and 4 similarity is: 0.478823\n",
      "the 10 and 7 similarity is: 0.320211\n",
      "the 10 and 8 similarity is: 0.456105\n",
      "2.918600629001803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(6, 2.9423719965834185), (10, 2.918600629001803), (5, 2.7635805374270137)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(Data,3,estMethod=svdEst)#推荐给uesr3的物品"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些人可能不太理解xformedItems = dataMat.T * U[:,:5] * Sig5.I为什么可以将数据转换到低维空间。\n",
    "\n",
    "我们知道dataMat是原始数据，U是左奇异矩阵，Sig是奇异值。我们也知道左奇异矩阵是单位正交矩阵，因此上面的运算可以看成是原始数据通过左奇异矩阵转换到了低维空间，然后取前几个最大的特征值。做过文本检索的同学应该对此比较熟悉。\n",
    "\n",
    "还有就是我们得到的xfromedItems它的维度是n \\times 5的。在这个时候行是代表物品而非用户，所以xformedItems[item,:].T与xformedItems[j,:].T计算物品的相似度。\n",
    "\n",
    "还有就是PCA和SVD都可以降维，那它们的不同之处在哪？\n",
    "\n",
    "注意到PCA先对矩阵做了中心化处理，然后再做Truncated SVD的(截断SVD)。\n",
    "\n",
    "如果矩阵本身就是中心化矩阵，那么PCA和Truncated SVD就是等价的。因此有一些库的PCA是通过SVD来实现的。\n",
    "\n",
    "构建推荐引擎还面临着一些问题\n",
    "\n",
    "首先SVD分解效率比较慢，在大型数据集上是一般是每天运行一次乃至几天运行一次。在代码中我们进行一次计算就运行了一次svd分解，这在现实中是不可能的。\n",
    "\n",
    "还有就是，实际的系统运用中用户数据中0的数目会更加的多。或许可以通过存储非零元素节省内存和计算开销。如：稀疏矩阵的三元组存储法。\n",
    "\n",
    "除此之外，我们的程序在需要一个推荐得分时，都要计算多个物品的相似度得分。在实际上，一个普遍的做法是离线计算并保存相似度得分。\n",
    "\n",
    "最大的问题是如何在缺乏数据的时候给出好的推荐。这个问题称作冷启动。书中说可以将推荐看成是搜索问题。在内部表现上，不同的解决方法有所不同，但是对用户而言都是透明的。为了将推荐看成是搜索问题，我们需要用到推荐物品的属性。比如：用各种标签来标记菜肴，素食、BBQ等。同时将这些属性作为相似度计算所需要的数据，这是基于内容的推荐。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 示例：基于SVD的图像压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei']#将字体更换成中文字体，解决plt中文显示问题\n",
    "\n",
    "def printMat(inMat, thresh=0.8):\n",
    "    '''\n",
    "    函数功能：打印32x32的矩阵\n",
    "    参数说明：\n",
    "            inMat__输入的矩阵\n",
    "            thresh__阈值\n",
    "    函数返回：\n",
    "            None\n",
    "    '''\n",
    "    for i in range(32):\n",
    "        for k in range(32):\n",
    "            #当数字小于阈值时，返回0。当数字大于阈值时返回1。end=' '是让它不要自动换行，并且打出空格符\n",
    "            if float(inMat[i,k]) > thresh:\n",
    "                print(1,end=' ')\n",
    "            else:\n",
    "                print(0,end=' ')\n",
    "        print('')#换行\n",
    "\n",
    "def loadPicData():#为了下面调用数据方便，将其读取数据流程单独放出来\n",
    "    '''\n",
    "    函数功能：加载32x32维的数据\n",
    "    参数说明：\n",
    "            None\n",
    "    函数返回：\n",
    "            32x32维的数据\n",
    "    '''\n",
    "    myl = []\n",
    "    #打开0_5.txt文件，逐行读取\n",
    "    for line in open('0_5.txt').readlines():\n",
    "        newRow = []\n",
    "        #隔32个字符截断一次。最后得到的是32x32矩阵\n",
    "        for i in range(32):\n",
    "            newRow.append(int(line[i]))\n",
    "        myl.append(newRow)\n",
    "    return myl\n",
    "\n",
    "def imgCompress(numSV=3, thresh=0.8):\n",
    "    '''\n",
    "    函数功能：打印32x32的矩阵\n",
    "    参数说明：\n",
    "            inMat__输入的矩阵\n",
    "            thresh__阈值\n",
    "    函数返回：\n",
    "            None\n",
    "    '''\n",
    "    myl = loadPicData()\n",
    "    myMat = np.mat(myl)\n",
    "    print(\"****original matrix******\")\n",
    "    printMat(myMat, thresh)\n",
    "    U,Sigma,VT = linalg.svd(myMat)\n",
    "    #构建一个3x3零矩阵\n",
    "    SigRecon = np.mat(np.zeros((numSV, numSV)))\n",
    "    #把奇异值赋值给这个3x3的矩阵构成对角矩阵\n",
    "    for k in range(numSV):\n",
    "        SigRecon[k,k] = Sigma[k]\n",
    "    #利用numSV个奇异值重构矩阵\n",
    "    reconMat = U[:,:numSV]*SigRecon*VT[:numSV,:]\n",
    "    print(\"****reconstructed matrix using %d singular values******\" % numSV)\n",
    "    printMat(reconMat, thresh)\n",
    "    \n",
    "    #图片对比\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(myMat,cmap='gray')\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(pd.DataFrame(reconMat).apply(lambda x:x>thresh),cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****original matrix******\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "****reconstructed matrix using 2 singular values******\n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 \n",
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgCompress(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "矩阵里包含了一个0字，可以看到重构的矩阵的0变得平整了一些。显然svd是一种有损的压缩，大家要根据需求使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 额外的展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 900x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = loadPicData()\n",
    "U,Sigma,VT = linalg.svd(data)\n",
    "\n",
    "total = np.sum(Sigma)\n",
    "num = Sigma.shape[0]\n",
    "s_rate = Sigma / total * 100\n",
    "\n",
    "plt.figure()#创建画布\n",
    "figsize(12.5, 5)#调整图片大小\n",
    "\n",
    "plt.subplot(1,2,1)#选择第一块区域\n",
    "plt.plot(np.arange(1,num+1,1),s_rate,\"-o\")#画出第一幅图\n",
    "plt.xlabel(\"第n个奇异值\")\n",
    "plt.ylabel(\"奇异值的大小\")\n",
    "\n",
    "plt.subplot(1,2,2)#选择第二块区域\n",
    "plt.plot(np.arange(1,num+1,1),[np.sum(s_rate[:i]) for i in range(num)],\"-o\")#画出第二幅图\n",
    "plt.xlabel(\"奇异值数量\")\n",
    "plt.ylabel(\"奇异值总和/总奇异值\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到奇异值大小下降是非常快的，而且前几个奇异值非常大，其包含的信息就越多。\n",
    "\n",
    "以上便是15章SVD要展示的所有的内容，感谢你的观看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
